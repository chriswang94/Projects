{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Prices in University Towns during the Recession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This analysis is inspired by a MOOC assignment.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This analysis explores the effect of the Recession on Housing Prices in University Towns.\n",
    "\n",
    "- The Recession time period is calculated by analyzing the change in the United States GDP quarter over quarter.  \n",
    "- A list of University Towns is scraped from a Wikipedia page.  \n",
    "- Housing Prices are analyzed on a quarter-by-quarter basis.  \n",
    "\n",
    "The hypothesis I am testing is that Housing Prices in University Towns were less affected by the Recession than Housing Prices in non-University Towns.  \n",
    "I employ a t-test to prove/disprove this hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions  \n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. GDP is pulled from an excel file provided by the Bureau of Economic Analysis.\n",
    "2. University Towns is scraped from the Wikipedia page (https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) via BeautifulSoup\n",
    "3. Housing Prices is extracted from a .csv file provided by Zillow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikiScrape(url):\n",
    "    # Return Wikipedia page as string\n",
    "    website_url = requests.get(url).text\n",
    "    \n",
    "    soup = BeautifulSoup(website_url,'lxml')\n",
    "    return soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStates(txt_list):\n",
    "    # Extract states from list    \n",
    "    states = pd.Series()\n",
    "    idx = 0\n",
    "    for i in range(len(txt_list)):\n",
    "        if \"edit\" in txt_list[i]:\n",
    "            states.at[i] = txt_list[i].replace(\"[edit]\",\"\")\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dothan</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Florence</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Homewood</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Huntsville</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Livingston</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Montevallo</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Montgomery</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Troy</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tuskegee</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Juneau</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ketchikan</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sitka</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Flagstaff</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Glendale</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lake Havasu City</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Prescott</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RegionName    State\n",
       "1             Auburn  Alabama\n",
       "2         Birmingham  Alabama\n",
       "3             Dothan  Alabama\n",
       "4           Florence  Alabama\n",
       "5           Homewood  Alabama\n",
       "6         Huntsville  Alabama\n",
       "7       Jacksonville  Alabama\n",
       "8         Livingston  Alabama\n",
       "9             Mobile  Alabama\n",
       "10        Montevallo  Alabama\n",
       "11        Montgomery  Alabama\n",
       "12              Troy  Alabama\n",
       "13        Tuscaloosa  Alabama\n",
       "14          Tuskegee  Alabama\n",
       "16         Anchorage   Alaska\n",
       "17         Fairbanks   Alaska\n",
       "18            Juneau   Alaska\n",
       "19         Ketchikan   Alaska\n",
       "20             Sitka   Alaska\n",
       "22          Chandler  Arizona\n",
       "23         Flagstaff  Arizona\n",
       "24           Gilbert  Arizona\n",
       "25          Glendale  Arizona\n",
       "26  Lake Havasu City  Arizona\n",
       "27              Mesa  Arizona\n",
       "28            Peoria  Arizona\n",
       "29           Phoenix  Arizona\n",
       "30          Prescott  Arizona\n",
       "31        Scottsdale  Arizona\n",
       "32             Tempe  Arizona"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getUniversityTowns():\n",
    "    # Scrape list of University Towns from Wikipedia\n",
    "    # Return as a dataframe\n",
    "    \n",
    "    #Scrape Wikipedia page\n",
    "    txt = wikiScrape('https://en.wikipedia.org/wiki/List_of_college_towns')\n",
    "    \n",
    "    # Extract relevant list of US College Towns\n",
    "    txt = txt[txt.find('Alabama[edit]'):txt.find('College towns in Argentina[edit]')]\n",
    "    txt_list = txt.splitlines()\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({'RegionName': txt_list})\n",
    "     \n",
    "    # Get Series of States\n",
    "    states = getStates(txt_list)\n",
    "    \n",
    "    # Add States to dataframe\n",
    "    df['State'] = states\n",
    "    df['State'].fillna(method = 'ffill', inplace = True)\n",
    "    df.drop(states.index, inplace = True)\n",
    "    \n",
    "    # Cleanse University Towns\n",
    "    df['RegionName'] = list(map(lambda x: x.split(\"(\")[0].rstrip(), df['RegionName']))\n",
    "    df['RegionName'] = list(map(lambda x: x.split(\"[\")[0].rstrip(), df['RegionName']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "preview = getUniversityTowns().head(30)\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGDP():\n",
    "    # Extract GDP data from excel file\n",
    "    gdp = pd.read_excel('gdplev.xls', skiprows = 5)\n",
    "    \n",
    "    # Rename and restructure dataframe\n",
    "    gdp.drop(gdp.index[0:214],inplace = True)\n",
    "    gdp = gdp[['Unnamed: 4', 'GDP in billions of chained 2009 dollars.1']]\n",
    "    gdp.columns = ['Quarter','GDP']\n",
    "    gdp.set_index(\"Quarter\", inplace = True)\n",
    "    \n",
    "    return gdp\n",
    "\n",
    "gdp = readGDP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008q3'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getRecessionStart(gdp):\n",
    "    # Find year, quarter when Recession began (2 consecutive years of GDP decline)\n",
    "    \n",
    "    # Calculate marginal GDP as a dataframe\n",
    "    gdp_change = gdp.diff()\n",
    "    \n",
    "    for i, quarter in enumerate(gdp_change.index):\n",
    "        if (gdp_change.iloc[i] < 0).bool() and (gdp_change.iloc[i+1] < 0).bool():\n",
    "            return quarter\n",
    "    return None  \n",
    "\n",
    "getRecessionStart(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009q4'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getRecessionEnd(gdp):\n",
    "    # Find year, quarter when Recession began \n",
    "    # (2 consecutive years of GDP growth after the Recession began)\n",
    "    \n",
    "    # Calculate marginal GDP as a dataframe\n",
    "    gdp_change = gdp.diff()\n",
    "    \n",
    "    # Only consider time period after Recession began\n",
    "    gdp_change = gdp_change.loc[(gdp_change.index >= getRecessionStart(gdp))]\n",
    "    \n",
    "    for i, quarter in enumerate(gdp_change.index):\n",
    "        if (gdp_change.iloc[i-1] > 0).bool() and (gdp_change.iloc[i] > 0).bool():\n",
    "            return quarter\n",
    "    return None  \n",
    "\n",
    "getRecessionEnd(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009q2'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getRecessionBottom(gdp):\n",
    "    # Returns year, quarter when GDP was lowest during the Recession\n",
    "    gdp = gdp.loc[(gdp.index >= getRecessionStart(gdp)) & (gdp.index <= getRecessionEnd(gdp))]\n",
    "    \n",
    "    return gdp.loc[gdp['GDP'] == gdp['GDP'].min()].index.item()\n",
    "\n",
    "getRecessionBottom(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToQuarters(col):\n",
    "    if col.endswith((\"01\", \"02\", \"03\")):\n",
    "        c = col[:4] + \"q1\"\n",
    "    elif col.endswith((\"04\", \"05\", \"06\")):\n",
    "        c = col[:4] + \"q2\"\n",
    "    elif col.endswith((\"07\", \"08\", \"09\")):\n",
    "        c = col[:4] + \"q3\"\n",
    "    else:\n",
    "        c = col[:4] + \"q4\"\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2000q1</th>\n",
       "      <th>2000q2</th>\n",
       "      <th>2000q3</th>\n",
       "      <th>2000q4</th>\n",
       "      <th>2001q1</th>\n",
       "      <th>2001q2</th>\n",
       "      <th>2001q3</th>\n",
       "      <th>2001q4</th>\n",
       "      <th>2002q1</th>\n",
       "      <th>2002q2</th>\n",
       "      <th>...</th>\n",
       "      <th>2014q2</th>\n",
       "      <th>2014q3</th>\n",
       "      <th>2014q4</th>\n",
       "      <th>2015q1</th>\n",
       "      <th>2015q2</th>\n",
       "      <th>2015q3</th>\n",
       "      <th>2015q4</th>\n",
       "      <th>2016q1</th>\n",
       "      <th>2016q2</th>\n",
       "      <th>2016q3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">Alabama</th>\n",
       "      <th>Adamsville</th>\n",
       "      <td>69033.333333</td>\n",
       "      <td>69166.666667</td>\n",
       "      <td>69800.000000</td>\n",
       "      <td>71966.666667</td>\n",
       "      <td>73466.666667</td>\n",
       "      <td>74000.000000</td>\n",
       "      <td>73333.333333</td>\n",
       "      <td>73100.000000</td>\n",
       "      <td>73333.333333</td>\n",
       "      <td>73133.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>77066.666667</td>\n",
       "      <td>75966.666667</td>\n",
       "      <td>71900.000000</td>\n",
       "      <td>71666.666667</td>\n",
       "      <td>73033.333333</td>\n",
       "      <td>73933.333333</td>\n",
       "      <td>73866.666667</td>\n",
       "      <td>74166.666667</td>\n",
       "      <td>74933.333333</td>\n",
       "      <td>74700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabaster</th>\n",
       "      <td>122133.333333</td>\n",
       "      <td>123066.666667</td>\n",
       "      <td>123166.666667</td>\n",
       "      <td>123700.000000</td>\n",
       "      <td>123233.333333</td>\n",
       "      <td>125133.333333</td>\n",
       "      <td>127766.666667</td>\n",
       "      <td>127200.000000</td>\n",
       "      <td>127300.000000</td>\n",
       "      <td>128000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>147133.333333</td>\n",
       "      <td>147633.333333</td>\n",
       "      <td>148700.000000</td>\n",
       "      <td>148900.000000</td>\n",
       "      <td>149566.666667</td>\n",
       "      <td>150366.666667</td>\n",
       "      <td>151733.333333</td>\n",
       "      <td>153466.666667</td>\n",
       "      <td>155100.000000</td>\n",
       "      <td>155850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albertville</th>\n",
       "      <td>73966.666667</td>\n",
       "      <td>72600.000000</td>\n",
       "      <td>72833.333333</td>\n",
       "      <td>74200.000000</td>\n",
       "      <td>75900.000000</td>\n",
       "      <td>76000.000000</td>\n",
       "      <td>72066.666667</td>\n",
       "      <td>73566.666667</td>\n",
       "      <td>76533.333333</td>\n",
       "      <td>76366.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>84033.333333</td>\n",
       "      <td>84766.666667</td>\n",
       "      <td>86800.000000</td>\n",
       "      <td>88466.666667</td>\n",
       "      <td>89500.000000</td>\n",
       "      <td>90233.333333</td>\n",
       "      <td>91366.666667</td>\n",
       "      <td>92000.000000</td>\n",
       "      <td>92466.666667</td>\n",
       "      <td>92200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arab</th>\n",
       "      <td>83766.666667</td>\n",
       "      <td>81566.666667</td>\n",
       "      <td>81333.333333</td>\n",
       "      <td>82966.666667</td>\n",
       "      <td>84200.000000</td>\n",
       "      <td>84533.333333</td>\n",
       "      <td>81666.666667</td>\n",
       "      <td>83900.000000</td>\n",
       "      <td>87266.666667</td>\n",
       "      <td>87700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>113366.666667</td>\n",
       "      <td>111700.000000</td>\n",
       "      <td>111600.000000</td>\n",
       "      <td>110166.666667</td>\n",
       "      <td>109433.333333</td>\n",
       "      <td>110900.000000</td>\n",
       "      <td>112233.333333</td>\n",
       "      <td>110033.333333</td>\n",
       "      <td>110100.000000</td>\n",
       "      <td>112000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ardmore</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>140533.333333</td>\n",
       "      <td>139566.666667</td>\n",
       "      <td>140900.000000</td>\n",
       "      <td>143233.333333</td>\n",
       "      <td>143000.000000</td>\n",
       "      <td>144600.000000</td>\n",
       "      <td>143966.666667</td>\n",
       "      <td>142566.666667</td>\n",
       "      <td>143233.333333</td>\n",
       "      <td>141950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Axis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>111066.666667</td>\n",
       "      <td>111833.333333</td>\n",
       "      <td>111800.000000</td>\n",
       "      <td>109533.333333</td>\n",
       "      <td>109666.666667</td>\n",
       "      <td>110033.333333</td>\n",
       "      <td>109600.000000</td>\n",
       "      <td>110266.666667</td>\n",
       "      <td>112200.000000</td>\n",
       "      <td>112750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baileyton</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>87666.666667</td>\n",
       "      <td>90033.333333</td>\n",
       "      <td>94100.000000</td>\n",
       "      <td>94600.000000</td>\n",
       "      <td>95666.666667</td>\n",
       "      <td>96833.333333</td>\n",
       "      <td>97233.333333</td>\n",
       "      <td>96766.666667</td>\n",
       "      <td>98900.000000</td>\n",
       "      <td>102200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bay Minette</th>\n",
       "      <td>81700.000000</td>\n",
       "      <td>78533.333333</td>\n",
       "      <td>79133.333333</td>\n",
       "      <td>81300.000000</td>\n",
       "      <td>85700.000000</td>\n",
       "      <td>87266.666667</td>\n",
       "      <td>85900.000000</td>\n",
       "      <td>85000.000000</td>\n",
       "      <td>84066.666667</td>\n",
       "      <td>84566.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>113333.333333</td>\n",
       "      <td>110600.000000</td>\n",
       "      <td>109900.000000</td>\n",
       "      <td>111100.000000</td>\n",
       "      <td>114300.000000</td>\n",
       "      <td>118533.333333</td>\n",
       "      <td>121433.333333</td>\n",
       "      <td>120266.666667</td>\n",
       "      <td>118333.333333</td>\n",
       "      <td>118500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayou La Batre</th>\n",
       "      <td>44066.666667</td>\n",
       "      <td>44500.000000</td>\n",
       "      <td>44266.666667</td>\n",
       "      <td>43666.666667</td>\n",
       "      <td>42500.000000</td>\n",
       "      <td>43333.333333</td>\n",
       "      <td>45433.333333</td>\n",
       "      <td>45400.000000</td>\n",
       "      <td>45400.000000</td>\n",
       "      <td>45566.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>49800.000000</td>\n",
       "      <td>51000.000000</td>\n",
       "      <td>51766.666667</td>\n",
       "      <td>50733.333333</td>\n",
       "      <td>50500.000000</td>\n",
       "      <td>50133.333333</td>\n",
       "      <td>48933.333333</td>\n",
       "      <td>48566.666667</td>\n",
       "      <td>47833.333333</td>\n",
       "      <td>47400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bessemer</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>54600.000000</td>\n",
       "      <td>55333.333333</td>\n",
       "      <td>54733.333333</td>\n",
       "      <td>55200.000000</td>\n",
       "      <td>57200.000000</td>\n",
       "      <td>58633.333333</td>\n",
       "      <td>59433.333333</td>\n",
       "      <td>59766.666667</td>\n",
       "      <td>59866.666667</td>\n",
       "      <td>59800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Birmingham</th>\n",
       "      <td>54033.333333</td>\n",
       "      <td>54400.000000</td>\n",
       "      <td>54966.666667</td>\n",
       "      <td>56066.666667</td>\n",
       "      <td>56833.333333</td>\n",
       "      <td>57600.000000</td>\n",
       "      <td>58433.333333</td>\n",
       "      <td>58700.000000</td>\n",
       "      <td>59500.000000</td>\n",
       "      <td>59866.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>61733.333333</td>\n",
       "      <td>60900.000000</td>\n",
       "      <td>59533.333333</td>\n",
       "      <td>59900.000000</td>\n",
       "      <td>61966.666667</td>\n",
       "      <td>62666.666667</td>\n",
       "      <td>63100.000000</td>\n",
       "      <td>62033.333333</td>\n",
       "      <td>61633.333333</td>\n",
       "      <td>61250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boaz</th>\n",
       "      <td>70866.666667</td>\n",
       "      <td>70266.666667</td>\n",
       "      <td>70300.000000</td>\n",
       "      <td>71466.666667</td>\n",
       "      <td>72833.333333</td>\n",
       "      <td>71900.000000</td>\n",
       "      <td>68733.333333</td>\n",
       "      <td>69833.333333</td>\n",
       "      <td>72766.666667</td>\n",
       "      <td>72100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80933.333333</td>\n",
       "      <td>81866.666667</td>\n",
       "      <td>82866.666667</td>\n",
       "      <td>83966.666667</td>\n",
       "      <td>85266.666667</td>\n",
       "      <td>86033.333333</td>\n",
       "      <td>86566.666667</td>\n",
       "      <td>85966.666667</td>\n",
       "      <td>87366.666667</td>\n",
       "      <td>88600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>92933.333333</td>\n",
       "      <td>94333.333333</td>\n",
       "      <td>96166.666667</td>\n",
       "      <td>98333.333333</td>\n",
       "      <td>96533.333333</td>\n",
       "      <td>98500.000000</td>\n",
       "      <td>99366.666667</td>\n",
       "      <td>104100.000000</td>\n",
       "      <td>103800.000000</td>\n",
       "      <td>102533.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>93866.666667</td>\n",
       "      <td>97100.000000</td>\n",
       "      <td>100100.000000</td>\n",
       "      <td>102433.333333</td>\n",
       "      <td>101800.000000</td>\n",
       "      <td>97900.000000</td>\n",
       "      <td>95600.000000</td>\n",
       "      <td>94433.333333</td>\n",
       "      <td>91366.666667</td>\n",
       "      <td>87650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brighton</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45366.666667</td>\n",
       "      <td>45133.333333</td>\n",
       "      <td>43766.666667</td>\n",
       "      <td>42500.000000</td>\n",
       "      <td>44233.333333</td>\n",
       "      <td>46266.666667</td>\n",
       "      <td>45766.666667</td>\n",
       "      <td>45033.333333</td>\n",
       "      <td>44433.333333</td>\n",
       "      <td>44000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brookwood</th>\n",
       "      <td>92566.666667</td>\n",
       "      <td>95100.000000</td>\n",
       "      <td>98866.666667</td>\n",
       "      <td>99966.666667</td>\n",
       "      <td>101666.666667</td>\n",
       "      <td>103666.666667</td>\n",
       "      <td>101833.333333</td>\n",
       "      <td>99900.000000</td>\n",
       "      <td>99633.333333</td>\n",
       "      <td>100366.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>106633.333333</td>\n",
       "      <td>110233.333333</td>\n",
       "      <td>114366.666667</td>\n",
       "      <td>117700.000000</td>\n",
       "      <td>118700.000000</td>\n",
       "      <td>120066.666667</td>\n",
       "      <td>118533.333333</td>\n",
       "      <td>115233.333333</td>\n",
       "      <td>111966.666667</td>\n",
       "      <td>108650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               2000q1         2000q2         2000q3  \\\n",
       "State   RegionName                                                    \n",
       "Alabama Adamsville       69033.333333   69166.666667   69800.000000   \n",
       "        Alabaster       122133.333333  123066.666667  123166.666667   \n",
       "        Albertville      73966.666667   72600.000000   72833.333333   \n",
       "        Arab             83766.666667   81566.666667   81333.333333   \n",
       "        Ardmore                   NaN            NaN            NaN   \n",
       "        Axis                      NaN            NaN            NaN   \n",
       "        Baileyton                 NaN            NaN            NaN   \n",
       "        Bay Minette      81700.000000   78533.333333   79133.333333   \n",
       "        Bayou La Batre   44066.666667   44500.000000   44266.666667   \n",
       "        Bessemer                  NaN            NaN            NaN   \n",
       "        Birmingham       54033.333333   54400.000000   54966.666667   \n",
       "        Boaz             70866.666667   70266.666667   70300.000000   \n",
       "        Brent            92933.333333   94333.333333   96166.666667   \n",
       "        Brighton                  NaN            NaN            NaN   \n",
       "        Brookwood        92566.666667   95100.000000   98866.666667   \n",
       "\n",
       "                               2000q4         2001q1         2001q2  \\\n",
       "State   RegionName                                                    \n",
       "Alabama Adamsville       71966.666667   73466.666667   74000.000000   \n",
       "        Alabaster       123700.000000  123233.333333  125133.333333   \n",
       "        Albertville      74200.000000   75900.000000   76000.000000   \n",
       "        Arab             82966.666667   84200.000000   84533.333333   \n",
       "        Ardmore                   NaN            NaN            NaN   \n",
       "        Axis                      NaN            NaN            NaN   \n",
       "        Baileyton                 NaN            NaN            NaN   \n",
       "        Bay Minette      81300.000000   85700.000000   87266.666667   \n",
       "        Bayou La Batre   43666.666667   42500.000000   43333.333333   \n",
       "        Bessemer                  NaN            NaN            NaN   \n",
       "        Birmingham       56066.666667   56833.333333   57600.000000   \n",
       "        Boaz             71466.666667   72833.333333   71900.000000   \n",
       "        Brent            98333.333333   96533.333333   98500.000000   \n",
       "        Brighton                  NaN            NaN            NaN   \n",
       "        Brookwood        99966.666667  101666.666667  103666.666667   \n",
       "\n",
       "                               2001q3         2001q4         2002q1  \\\n",
       "State   RegionName                                                    \n",
       "Alabama Adamsville       73333.333333   73100.000000   73333.333333   \n",
       "        Alabaster       127766.666667  127200.000000  127300.000000   \n",
       "        Albertville      72066.666667   73566.666667   76533.333333   \n",
       "        Arab             81666.666667   83900.000000   87266.666667   \n",
       "        Ardmore                   NaN            NaN            NaN   \n",
       "        Axis                      NaN            NaN            NaN   \n",
       "        Baileyton                 NaN            NaN            NaN   \n",
       "        Bay Minette      85900.000000   85000.000000   84066.666667   \n",
       "        Bayou La Batre   45433.333333   45400.000000   45400.000000   \n",
       "        Bessemer                  NaN            NaN            NaN   \n",
       "        Birmingham       58433.333333   58700.000000   59500.000000   \n",
       "        Boaz             68733.333333   69833.333333   72766.666667   \n",
       "        Brent            99366.666667  104100.000000  103800.000000   \n",
       "        Brighton                  NaN            NaN            NaN   \n",
       "        Brookwood       101833.333333   99900.000000   99633.333333   \n",
       "\n",
       "                               2002q2  ...         2014q2         2014q3  \\\n",
       "State   RegionName                     ...                                 \n",
       "Alabama Adamsville       73133.333333  ...   77066.666667   75966.666667   \n",
       "        Alabaster       128000.000000  ...  147133.333333  147633.333333   \n",
       "        Albertville      76366.666667  ...   84033.333333   84766.666667   \n",
       "        Arab             87700.000000  ...  113366.666667  111700.000000   \n",
       "        Ardmore                   NaN  ...  140533.333333  139566.666667   \n",
       "        Axis                      NaN  ...  111066.666667  111833.333333   \n",
       "        Baileyton                 NaN  ...   87666.666667   90033.333333   \n",
       "        Bay Minette      84566.666667  ...  113333.333333  110600.000000   \n",
       "        Bayou La Batre   45566.666667  ...   49800.000000   51000.000000   \n",
       "        Bessemer                  NaN  ...   54600.000000   55333.333333   \n",
       "        Birmingham       59866.666667  ...   61733.333333   60900.000000   \n",
       "        Boaz             72100.000000  ...   80933.333333   81866.666667   \n",
       "        Brent           102533.333333  ...   93866.666667   97100.000000   \n",
       "        Brighton                  NaN  ...   45366.666667   45133.333333   \n",
       "        Brookwood       100366.666667  ...  106633.333333  110233.333333   \n",
       "\n",
       "                               2014q4         2015q1         2015q2  \\\n",
       "State   RegionName                                                    \n",
       "Alabama Adamsville       71900.000000   71666.666667   73033.333333   \n",
       "        Alabaster       148700.000000  148900.000000  149566.666667   \n",
       "        Albertville      86800.000000   88466.666667   89500.000000   \n",
       "        Arab            111600.000000  110166.666667  109433.333333   \n",
       "        Ardmore         140900.000000  143233.333333  143000.000000   \n",
       "        Axis            111800.000000  109533.333333  109666.666667   \n",
       "        Baileyton        94100.000000   94600.000000   95666.666667   \n",
       "        Bay Minette     109900.000000  111100.000000  114300.000000   \n",
       "        Bayou La Batre   51766.666667   50733.333333   50500.000000   \n",
       "        Bessemer         54733.333333   55200.000000   57200.000000   \n",
       "        Birmingham       59533.333333   59900.000000   61966.666667   \n",
       "        Boaz             82866.666667   83966.666667   85266.666667   \n",
       "        Brent           100100.000000  102433.333333  101800.000000   \n",
       "        Brighton         43766.666667   42500.000000   44233.333333   \n",
       "        Brookwood       114366.666667  117700.000000  118700.000000   \n",
       "\n",
       "                               2015q3         2015q4         2016q1  \\\n",
       "State   RegionName                                                    \n",
       "Alabama Adamsville       73933.333333   73866.666667   74166.666667   \n",
       "        Alabaster       150366.666667  151733.333333  153466.666667   \n",
       "        Albertville      90233.333333   91366.666667   92000.000000   \n",
       "        Arab            110900.000000  112233.333333  110033.333333   \n",
       "        Ardmore         144600.000000  143966.666667  142566.666667   \n",
       "        Axis            110033.333333  109600.000000  110266.666667   \n",
       "        Baileyton        96833.333333   97233.333333   96766.666667   \n",
       "        Bay Minette     118533.333333  121433.333333  120266.666667   \n",
       "        Bayou La Batre   50133.333333   48933.333333   48566.666667   \n",
       "        Bessemer         58633.333333   59433.333333   59766.666667   \n",
       "        Birmingham       62666.666667   63100.000000   62033.333333   \n",
       "        Boaz             86033.333333   86566.666667   85966.666667   \n",
       "        Brent            97900.000000   95600.000000   94433.333333   \n",
       "        Brighton         46266.666667   45766.666667   45033.333333   \n",
       "        Brookwood       120066.666667  118533.333333  115233.333333   \n",
       "\n",
       "                               2016q2    2016q3  \n",
       "State   RegionName                               \n",
       "Alabama Adamsville       74933.333333   74700.0  \n",
       "        Alabaster       155100.000000  155850.0  \n",
       "        Albertville      92466.666667   92200.0  \n",
       "        Arab            110100.000000  112000.0  \n",
       "        Ardmore         143233.333333  141950.0  \n",
       "        Axis            112200.000000  112750.0  \n",
       "        Baileyton        98900.000000  102200.0  \n",
       "        Bay Minette     118333.333333  118500.0  \n",
       "        Bayou La Batre   47833.333333   47400.0  \n",
       "        Bessemer         59866.666667   59800.0  \n",
       "        Birmingham       61633.333333   61250.0  \n",
       "        Boaz             87366.666667   88600.0  \n",
       "        Brent            91366.666667   87650.0  \n",
       "        Brighton         44433.333333   44000.0  \n",
       "        Brookwood       111966.666667  108650.0  \n",
       "\n",
       "[15 rows x 67 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getHousing():\n",
    "    # Creates dataframe with Housing info\n",
    "    \n",
    "    states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}\n",
    "    \n",
    "    house = pd.read_csv('City_Zhvi_AllHomes.csv')\n",
    "    \n",
    "    # Structure dataframe; group by State and Town \n",
    "    house['State'].replace(states,inplace=True)\n",
    "    house.set_index(['State','RegionName'],inplace = True)\n",
    "    house = house.sort_index()\n",
    "    \n",
    "    # Remove unneeded columns (i.e. data related to years prior to January, 2000)\n",
    "    house = house.iloc[:, 49:250]\n",
    "    \n",
    "    # Group months into quarters; average housing prices\n",
    "    house = house.groupby(convertToQuarters, axis = 1).mean()\n",
    "    \n",
    "    return house\n",
    "\n",
    "preview = getHousing().head(15)\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 4.210723869029692e-08, 'non-university town')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def t_testing():\n",
    "    # Get University Towns\n",
    "    univTowns = getUniversityTowns()\n",
    "    # Index by State and Town\n",
    "    univTowns.set_index(['State','RegionName'], inplace = True)\n",
    "\n",
    "    # Get GDP data|\n",
    "    gdp = getGDP()\n",
    "    QBeforeRec = getRecessionStart(gdp)\n",
    "    QRecBottom = getRecessionBottom(gdp)\n",
    "    QAfterRec = getRecessionEnd(gdp)\n",
    "    \n",
    "    # Get Housing Prices data\n",
    "    house = getHousing()\n",
    "    house = house[[QBeforeRec,QRecBottom]].dropna()\n",
    "    house['ratio'] = house[QBeforeRec]/house[QRecBottom]\n",
    "    \n",
    "    \n",
    "    # Split Housing Prices into University Town and Non-University Town\n",
    "    univ_house = pd.merge(univTowns, house, how = 'inner', left_index = True, right_index = True)\n",
    "    non_univ_house = house[~house.index.isin(univ_house.index)]\n",
    "    ## Verified that there all towns listed in University Towns dataset are included in list of towns in Housing Prices data\n",
    "    \n",
    "    # Run statistical analysis\n",
    "    t_stat, p_value = ttest_ind(univ_house[\"ratio\"], non_univ_house[\"ratio\"])\n",
    "\n",
    "    if p_value < 0.01:\n",
    "        different = True\n",
    "    else:\n",
    "        different = False\n",
    "    if t_stat < 0:\n",
    "        better = \"university town\"\n",
    "    else:\n",
    "        better = \"non-university town\"\n",
    "    return (different, p_value, better)\n",
    "\n",
    "t_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "1. Scope of analysis is limited to quarter-by-quarter time periods as that is the deepest level of information provided - limited by GDP\n",
    "2. I averaged housing prices rather than added them as I am comparing housing prices of individual homes; averaging prices prevents distortion by number of houses in each town"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value less than .01, we reject the null hypothesis that the Recession affected housing prices equally between University Towns and Non-University Towns.  \n",
    "Furthermore, the t-stat was positive, indicating price ratio for the University Towns is more than that of the Non-University Towns. In other words, Housing Prices in Non-University Towns were less affected by the recession.\n",
    "\n",
    "However, since Wikipedia is constantly updated. The list of University Towns pulled directly from the site most likely does not accurately reflect which towns were University Towns during the Recession. Indeed, the number of University Towns pulled during this analysis neared 1000 in number whereas the text file provided by the MOOC listed approximately half that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing an Alternate Data Source\n",
    "\n",
    "Below, I will utilize the list provided by the MOOC to perform my analysis to investigate the potential difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a DataFrame of towns and the states they are in from the \n",
    "    university_towns.txt list. The format of the DataFrame should be:\n",
    "    DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "    columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "    The following cleaning needs to be done:\n",
    "\n",
    "    1. For \"State\", removing characters from \"[\" to the end.\n",
    "    2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "    3. Depending on how you read the data, you may need to remove newline character '\\n'. '''\n",
    "    \n",
    "    text_file = open(\"university_towns.txt\")\n",
    "\n",
    "    states = pd.Series({idx: lines.strip().replace(\"[edit]\", \"\")\n",
    "             for idx,lines in enumerate(text_file) if \"edit\" in lines})\n",
    "    \n",
    "    univ_town = pd.read_csv('university_towns.txt', sep = '\\n', header = None)\n",
    "    univ_town.rename(columns = {univ_town.columns[0] : 'RegionName'}, inplace = True)\n",
    "\n",
    "    \n",
    "    univ_town['State'] = states\n",
    "\n",
    "    univ_town=univ_town.fillna(method='ffill')\n",
    "    univ_town=univ_town.drop(states.index)\n",
    "    \n",
    "    univ_town['RegionName'] = list(map(lambda x: x.split(\"(\")[0].rstrip(),univ_town['RegionName']))\n",
    "    \n",
    "    #univ_town.set_index(['State', 'RegionName'], inplace = True)\n",
    "    \n",
    "    return univ_town\n",
    "\n",
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.005496427353694603, 'university town')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def t_testing():\n",
    "    # Get University Towns\n",
    "    univTowns = get_list_of_university_towns()\n",
    "    # Index by State and Town\n",
    "    univTowns.set_index(['State','RegionName'], inplace = True)\n",
    "\n",
    "    # Get GDP data|\n",
    "    gdp = getGDP()\n",
    "    QBeforeRec = getRecessionStart(gdp)\n",
    "    QRecBottom = getRecessionBottom(gdp)\n",
    "    QAfterRec = getRecessionEnd(gdp)\n",
    "    \n",
    "    # Get Housing Prices data\n",
    "    house = getHousing()\n",
    "    house = house[[QBeforeRec,QRecBottom]].dropna()\n",
    "    house['ratio'] = house[QBeforeRec]/house[QRecBottom]\n",
    "    \n",
    "    \n",
    "    # Split Housing Prices into University Town and Non-University Town\n",
    "    univ_house = pd.merge(univTowns, house, how = 'inner', left_index = True, right_index = True)\n",
    "    non_univ_house = house[~house.index.isin(univ_house.index)]\n",
    "    ## Verified that there all towns listed in University Towns dataset are included in list of towns in Housing Prices data\n",
    "    \n",
    "    # Run statistical analysis\n",
    "    t_stat, p_value = ttest_ind(univ_house[\"ratio\"], non_univ_house[\"ratio\"])\n",
    "\n",
    "    if p_value < 0.01:\n",
    "        different = True\n",
    "    else:\n",
    "        different = False\n",
    "    if t_stat < 0:\n",
    "        better = \"university town\"\n",
    "    else:\n",
    "        better = \"non-university town\"\n",
    "    return (different, p_value, better)\n",
    "\n",
    "t_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-up\n",
    "\n",
    "Confirming my assumption, the the results changed significantly - altering the decision result. Now, with a smaller list of University Towns, we see that the t-stat is become negative, indicating that Housing Prices in University Towns were less affected by the Recession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
